{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d430f0",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "## Integrated Project: Understanding Maji Ndogo's agriculture\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this coding challenge, we will apply all of the skills we learned in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "⚠️ **Note that this code challenge is graded and will contribute to your overall marks for this module. Submit this notebook for grading. Note that the names of the functions are different in this notebook. Transfer the code in your notebook to this submission notebook**\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- **Do not add or remove cells in this notebook. Do not edit or remove the `### START FUNCTION` or `### END FUNCTION` comments. Do not add any code outside of the functions you are required to edit. Doing any of this will lead to a mark of 0%!**\n",
    "\n",
    "- Answer the questions according to the specifications provided.\n",
    "\n",
    "- Use the given cell in each question to see if your function matches the expected outputs.\n",
    "\n",
    "- Do not hard-code answers to the questions.\n",
    "\n",
    "- The use of StackOverflow, Google, and other online tools is permitted. However, copying a fellow student's code is not permissible and is considered a breach of the Honour code. Doing this will result in a mark of 0%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944ccbc",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e633f",
   "metadata": {},
   "source": [
    "Hey there, I'm glad you're on board for the Maji Ndogo project AGAIN! Let me walk you through what we're up against and how we'll tackle it.\n",
    "\n",
    "As you know, we're in an ambitious project aimed at automating farming in Maji Ndogo, a place with diverse and challenging agricultural landscapes. Before we dive into the 'how' of farming, we need to figure out the 'where' and 'what'. It's not just about deploying technology; it's about making informed decisions on where to plant specific crops, considering factors like rainfall, soil type, climate, and many others.\n",
    "\n",
    "Our analysis is the groundwork for this entire automation project. We have an array of variables like soil fertility, climate conditions, and geographical data. By understanding these elements, we can recommend the best locations for different crops. It's a bit like solving a complex puzzle – each piece of data is crucial to seeing the bigger picture.\n",
    "\n",
    "We'll start by importing our dataset into a DataFrame. It is currently in an SQLite database, and split into tables. Unlike Power BI or SQL, data analysis in Python happens in a single table. So we will have to brush off those dusty SQL skills to get the data imported. Expect a bit of a mess in the data – it's part of the challenge. We need to clean it up and maybe reshape it to make sense of it. It's like sorting out the tools and materials we need and getting rid of what we don't.\n",
    "\n",
    "Here's where the real fun begins. We'll dive deep into the data, looking for patterns, and correlations. Each clue in the data leads us closer to understanding the best farming practices for Maji Ndogo. I'll be relying on your skills and insights. We'll be working through these steps together, discussing our findings and strategies.\n",
    "\n",
    "Let's gear up and get ready to make a real difference in Maji Ndogo. Ready to get started? Let's dive into our data and see what stories it has to tell us.\n",
    "\n",
    "Sanaa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147be850",
   "metadata": {},
   "source": [
    "# Data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8e55e",
   "metadata": {},
   "source": [
    "**1. Geographic features**\n",
    "\n",
    "- **Field_ID:** A unique identifier for each field (BigInt).\n",
    " \n",
    "- **Elevation:** The elevation of the field above sea level in metres (Float).\n",
    "\n",
    "- **Latitude:** Geographical latitude of the field in degrees (Float).\n",
    "\n",
    "- **Longitude:** Geographical longitude of the field in degrees (Float).\n",
    "\n",
    "- **Location:** Province the field is in (Text).\n",
    "\n",
    "- **Slope:** The slope of the land in the field (Float).\n",
    "\n",
    "**2. Weather features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Rainfall:** Amount of rainfall in the area in mm (Float).\n",
    "\n",
    "- **Min_temperature_C:** Average minimum temperature recorded in Celsius (Float).\n",
    "\n",
    "- **Max_temperature_C:** Average maximum temperature recorded in Celsius (Float).\n",
    "\n",
    "- **Ave_temps:** Average temperature in Celcius (Float).\n",
    "\n",
    "**3. Soil and crop features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Soil_fertility:** A measure of soil fertility where 0 is infertile soil, and 1 is very fertile soil (Float).\n",
    "\n",
    "- **Soil_type:** Type of soil present in the field (Text).\n",
    "\n",
    "- **pH:** pH level of the soil, which is a measure of how acidic/basic the soil is (Float).\n",
    "\n",
    "**4. Farm management features**\n",
    "\n",
    "- **Field_ID:** Corresponding field identifier (BigInt).\n",
    "\n",
    "- **Pollution_level:** Level of pollution in the area where 0 is unpolluted and 1 is very polluted (Float).\n",
    "\n",
    "- **Plot_size:** Size of the plot in the field (Ha) (Float).\n",
    "\n",
    "- **Chosen_crop:** Type of crop chosen for cultivation (Text).\n",
    "\n",
    "- **Annual_yield:** Annual yield from the field (Float). This is the total output of the field. The field size and type of crop will affect the Annual Yield\n",
    "\n",
    "- **Standard_yield:** Standardised yield expected from the field, normalised per crop (Float). This is independent of field size, or crop type. Multiplying this number by the field size, and average crop yield will give the Annual_Yield."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f0f12",
   "metadata": {},
   "source": [
    "**Average yield (tons/Ha) per crop type:**\n",
    "- **Coffee:** 1.5 \n",
    "\n",
    "- **Wheat:** 3\n",
    "\n",
    "- **Rice:** 4.5\n",
    "\n",
    "- **Maize:** 5.5\n",
    "\n",
    "- **Tea:** 1.2\n",
    "\n",
    "- **Potato:** 20\n",
    "\n",
    "- **Banana:** 30\n",
    "\n",
    "- **Cassava:** 13\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b39b1a",
   "metadata": {},
   "source": [
    "Alright, let's walk through the process of importing our SQL data from multiple tables into a single DataFrame. This is a crucial step as it sets the foundation for all our subsequent analyses.\n",
    "\n",
    "We're dealing with an SQLite database, `Maji_Ndogo_farm_survey.db`, which contains multiple tables. We'll need to join these tables on a common key to create a comprehensive dataset for our analysis. The common key in our case is `Field_ID`.\n",
    "\n",
    "Here’s how we can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aedfcf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # importing the Pandas package with an alias, pd\n",
    "from sqlalchemy import create_engine, text # Importing the SQL interface. If this fails, run !pip install sqlalchemy in another cell.\n",
    "\n",
    "# Create an engine for the database\n",
    "engine = create_engine('sqlite:///Maji_Ndogo_farm_survey_small.db') #Make sure to have the .db file in the same directory as this notebook, and the file name matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b71f19",
   "metadata": {},
   "source": [
    "Next up, we test if the connection works by printing out all of the table names in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ee695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT name FROM sqlite_master WHERE type='table';\"))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5838b83",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "`('geographic_features',)`\n",
    "\n",
    "`('weather_features',)`\n",
    "\n",
    "`('soil_and_crop_features',)`\n",
    "\n",
    "`('farm_management_features',)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2023f",
   "metadata": {},
   "source": [
    "At this point, we have two choices:\n",
    "\n",
    "1. Either we import each table into a DataFrame, for example, `df_geographic`, then merge them together.\n",
    "\n",
    "2. Use one SQL query and read it into a single DataFrame.\n",
    "\n",
    "While both are equally viable, let's try to use a single SQL query to keep things simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9cd3cf",
   "metadata": {},
   "source": [
    "Next, we'll write an SQL query to join our tables. Combine all of the tables into a single query, using `Field_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6a0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT *\n",
    "FROM geographic_features as g\n",
    "JOIN weather_features as w\n",
    "ON g.Field_ID = w.Field_ID\n",
    "JOIN soil_and_crop_features as sc\n",
    "ON g.Field_ID = sc.Field_ID\n",
    "JOIN farm_management_features as fm\n",
    "ON g.Field_ID = fm.Field_ID;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c476ff1c",
   "metadata": {},
   "source": [
    "With our engine and query ready, we'll use `Pandas` to execute the query. The `pd.read_sql_query` function fetches the data and loads it into a DataFrame – essentially transferring our data from the database into a familiar `Pandas` structure. If you use one query, you will import it all into `MD_agric_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd4653b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: geographic_features\n[SQL: \nSELECT *\nFROM geographic_features as g\nJOIN weather_features as w\nON g.Field_ID = w.Field_ID\nJOIN soil_and_crop_features as sc\nON g.Field_ID = sc.Field_ID\nJOIN farm_management_features as fm\nON g.Field_ID = fm.Field_ID;\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1964\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1965\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 921\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: geographic_features",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a connection object\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[0;32m      3\u001b[0m     \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Use Pandas to execute the query and store the result in a DataFrame\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     MD_agric_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:397\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03mparameter will be converted to UTC.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    396\u001b[0m pandas_sql \u001b[38;5;241m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 1560\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1561\u001b[0m columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\io\\sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable\u001b[38;5;241m.\u001b[39mexecution_options()\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1412\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:516\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1635\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1623\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1624\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1625\u001b[0m )\n\u001b[0;32m   1627\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1628\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1629\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1633\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1634\u001b[0m )\n\u001b[1;32m-> 1635\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1648\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1649\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1650\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         ret,\n\u001b[0;32m   1655\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(\n\u001b[0;32m   1840\u001b[0m         dialect,\n\u001b[0;32m   1841\u001b[0m         context,\n\u001b[0;32m   1842\u001b[0m     )\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1846\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1984\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1984\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1985\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2339\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2338\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2341\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1963\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1964\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1965\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1970\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1971\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1972\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1976\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1977\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sqlalchemy\\engine\\default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 921\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: geographic_features\n[SQL: \nSELECT *\nFROM geographic_features as g\nJOIN weather_features as w\nON g.Field_ID = w.Field_ID\nJOIN soil_and_crop_features as sc\nON g.Field_ID = sc.Field_ID\nJOIN farm_management_features as fm\nON g.Field_ID = fm.Field_ID;\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "# Create a connection object\n",
    "with engine.connect() as connection:\n",
    "    \n",
    "    # Use Pandas to execute the query and store the result in a DataFrame\n",
    "    MD_agric_df = pd.read_sql_query(text(sql_query), connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171c658",
   "metadata": {},
   "source": [
    "Check the DataFrame to see if it loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e370c4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MD_agric_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mMD_agric_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MD_agric_df' is not defined"
     ]
    }
   ],
   "source": [
    "MD_agric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0cc230",
   "metadata": {},
   "source": [
    "Note that there are a couple of `Field_ID` columns in our DataFrame that we need to remove since we're not interested in particular farms for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, drop all columns named 'Field_ID'.\n",
    "MD_agric_df.drop(columns = 'Field_ID', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837de59",
   "metadata": {},
   "source": [
    "# Data cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2b362",
   "metadata": {},
   "source": [
    "I noticed some errors in the data. Here's what I picked up:\n",
    "\n",
    "1. There are some swapped column names. Please ensure to use the correct name. \n",
    "\n",
    "2. Some of the crop types contain spelling errors.\n",
    "\n",
    "3.  The `Elevation` column contains some negative values, which are not plausible, so change these to positive values.\n",
    "\n",
    "Use your Pandas skills to clean up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b22740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data clean up \n",
    "# 1. Fixing swapped columns names\n",
    "MD_agric_df.rename(columns = {\"Crop_type\":\"Annual_yield\", \"Annual_yield\":\"Crop_type\"}, inplace = True)\n",
    "\n",
    "# 2. Fixing misspelt crop type names\n",
    "MD_agric_df[\"Crop_type\"] = MD_agric_df[\"Crop_type\"].replace({'wheat ':'wheat', 'cassaval':'cassava', 'tea ':'tea', \n",
    "                                                             'wheatn':'wheat', 'cassava ':'cassava', 'teaa':'tea'})\n",
    "# 3. Change negative elevation column values to positive values\n",
    "MD_agric_df[\"Elevation\"] = MD_agric_df[\"Elevation\"].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c0fed1",
   "metadata": {},
   "source": [
    "## Final data checkup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fdc11",
   "metadata": {},
   "source": [
    "Compare your answers to the expected output to make sure your data is corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000a401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MD_agric_df['Crop_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8309f1",
   "metadata": {},
   "source": [
    "Expected output: `8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1371959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.910797"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD_agric_df['Elevation'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa4440",
   "metadata": {},
   "source": [
    "Expected output: `35.910797`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba5369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD_agric_df['Annual_yield'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697d96b",
   "metadata": {},
   "source": [
    "Expected outcome: `dtype('float64')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324a485",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fddb1",
   "metadata": {},
   "source": [
    "## Challenge 1: Uncovering crop preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b8dc1b",
   "metadata": {},
   "source": [
    "Now that we have our data ready, let's delve into understanding where different crops are grown in Maji Ndogo. Our initial step is to focus on tea, a key crop in Maji Ndogo. We need to determine the optimal conditions for its growth. By analyzing data related to elevation, rainfall, and soil type specifically for tea plantations, we'll start to paint a picture of where our farming systems could thrive.\n",
    "\n",
    "**Task:**\n",
    "Create a function that includes only tea fields and returns a tuple with the mean `Rainfall` and the mean `Elevation`. The function should input the full DataFrame, a string value for the crop type to filter by, and output a tuple with rainfall and elevation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86896dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def explore_crop_distribution(df,crop_filter):\n",
    "    # Filtering DF by the specified crop type\n",
    "    filtered_df = df[df['Crop_type'] == crop_filter]\n",
    "\n",
    "    # Calculating the mean Rainfall and mean Elevation for the filtered crop type\n",
    "    mean_rainfall = filtered_df['Rainfall'].mean()\n",
    "    mean_elevation = filtered_df['Elevation'].mean()\n",
    "\n",
    "    # Return the results as a tuple\n",
    "    return mean_rainfall, mean_elevation\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4474e",
   "metadata": {},
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca9510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1534.5079956188388, 775.208667535597)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_crop_distribution(MD_agric_df, \"tea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae64880",
   "metadata": {},
   "source": [
    "Expected output: `(1534.5079956188388, 775.208667535597)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d76595",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'explore_crop_distribution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mexplore_crop_distribution\u001b[49m(MD_agric_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwheat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'explore_crop_distribution' is not defined"
     ]
    }
   ],
   "source": [
    "explore_crop_distribution(MD_agric_df, \"wheat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cd8725",
   "metadata": {},
   "source": [
    "Expected output: `(1010.2859910581222, 595.8384148002981)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78795c87",
   "metadata": {},
   "source": [
    "Repeat this for a couple of crops to get a feeling for where crops are planted in Majio Ndogo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372ccb9",
   "metadata": {},
   "source": [
    "## Challenge 2: Finding fertile grounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c4cc1",
   "metadata": {},
   "source": [
    "With insights into tea cultivation, let's broaden our horizons. Fertile soil is the bedrock of successful farming. By grouping our data by location and soil type, we'll pinpoint where the most fertile soils in Maji Ndogo are. These fertile zones could be prime candidates for diverse crop cultivation, maximising our yield.\n",
    "\n",
    "We’ll group our data by soil type to see where the most fertile grounds are. This information will be vital for deciding where to deploy our farming technology.\n",
    "\n",
    "**Task:** Create a function that groups the data by `Soil_type`, and returns the `Soil_fertility`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def analyse_soil_fertility(df):\n",
    "    soil_fertility_by_type = df.groupby('Soil_type')['Soil_fertility'].mean()\n",
    "    return soil_fertility_by_type\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39424119",
   "metadata": {},
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11f72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Soil_type\n",
       "Loamy       0.585868\n",
       "Peaty       0.604882\n",
       "Rocky       0.582368\n",
       "Sandy       0.595669\n",
       "Silt        0.652654\n",
       "Volcanic    0.648894\n",
       "Name: Soil_fertility, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_soil_fertility(MD_agric_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a7f56",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "```python Soil_Type\n",
    "Loamy       0.585868\n",
    "Peaty       0.604882\n",
    "Rocky       0.582368\n",
    "Sandy       0.595669\n",
    "Silt        0.652654\n",
    "Volcanic    0.648894\n",
    "Name: Soil_Fertility, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1845f",
   "metadata": {},
   "source": [
    "Try digging into the data a bit more by aggregating various data to identify some more patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d8de9",
   "metadata": {},
   "source": [
    "## Challenge 3: Climate and geography analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc62613",
   "metadata": {},
   "source": [
    "Now, let's delve into how climate and geography influence farming. By understanding the relationship between factors like elevation, temperature, and rainfall with crop yields, we can identify the most suitable areas for different crops. This analysis is key to ensuring our automated systems are deployed in locations that will maximise their effectiveness.\n",
    "\n",
    "**Task:** Create a function that takes in a DataFrame and the column name, and groups the data by that column, and aggregates the data by the means of `Elevation`, `Min_temperature_C`, `Max_temperature_C`, and `Rainfall`, and outputs a DataFrame. Please ensure that the order of the columns matches the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29474e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def climate_geography_influence(df,column):\n",
    "    climate_geog = df.groupby(column).agg({\"Elevation\":\"mean\", \"Min_temperature_C\":\"mean\", \"Max_temperature_C\":\"mean\", \"Rainfall\":\"mean\"})\n",
    "    return climate_geog\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448a869",
   "metadata": {},
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c214f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Min_temperature_C</th>\n",
       "      <th>Max_temperature_C</th>\n",
       "      <th>Rainfall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crop_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>487.973572</td>\n",
       "      <td>-5.354344</td>\n",
       "      <td>31.988152</td>\n",
       "      <td>1659.905687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cassava</th>\n",
       "      <td>682.903008</td>\n",
       "      <td>-3.992113</td>\n",
       "      <td>30.902381</td>\n",
       "      <td>1210.543006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>647.047734</td>\n",
       "      <td>-4.028007</td>\n",
       "      <td>30.855189</td>\n",
       "      <td>1527.265074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maize</th>\n",
       "      <td>680.596982</td>\n",
       "      <td>-4.497995</td>\n",
       "      <td>30.576692</td>\n",
       "      <td>681.010276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potato</th>\n",
       "      <td>696.313917</td>\n",
       "      <td>-4.375334</td>\n",
       "      <td>30.300608</td>\n",
       "      <td>660.289064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rice</th>\n",
       "      <td>352.858053</td>\n",
       "      <td>-6.610566</td>\n",
       "      <td>32.727170</td>\n",
       "      <td>1632.382642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tea</th>\n",
       "      <td>775.208668</td>\n",
       "      <td>-2.862651</td>\n",
       "      <td>29.950383</td>\n",
       "      <td>1534.507996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wheat</th>\n",
       "      <td>595.838415</td>\n",
       "      <td>-4.968107</td>\n",
       "      <td>30.973845</td>\n",
       "      <td>1010.285991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Elevation  Min_temperature_C  Max_temperature_C     Rainfall\n",
       "Crop_type                                                               \n",
       "banana     487.973572          -5.354344          31.988152  1659.905687\n",
       "cassava    682.903008          -3.992113          30.902381  1210.543006\n",
       "coffee     647.047734          -4.028007          30.855189  1527.265074\n",
       "maize      680.596982          -4.497995          30.576692   681.010276\n",
       "potato     696.313917          -4.375334          30.300608   660.289064\n",
       "rice       352.858053          -6.610566          32.727170  1632.382642\n",
       "tea        775.208668          -2.862651          29.950383  1534.507996\n",
       "wheat      595.838415          -4.968107          30.973845  1010.285991"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_geography_influence(MD_agric_df, 'Crop_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ce1a4",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "```sql\n",
    "Crop_type \tElevation\tMin_temperature_C\tMax_temperature_C\tRainfall\t\t\t\n",
    "banana\t\t487.973572\t-5.354344\t\t31.988152\t    1659.905687\n",
    "cassava\t\t682.903008\t-3.992113\t\t30.902381\t    1210.543006\n",
    "coffee\t\t647.047734\t-4.028007\t\t30.855189\t    1527.265074\n",
    "maize\t\t680.596982\t-4.497995\t\t30.576692\t    681.010276\n",
    "potato\t\t696.313917\t-4.375334\t\t30.300608\t    660.289064\n",
    "rice\t\t352.858053\t-6.610566\t\t32.727170\t    1632.382642\n",
    "tea\t\t775.208668\t-2.862651\t\t29.950383\t    1534.507996\n",
    "wheat\t\t595.838415\t-4.968107\t\t30.973845\t    1010.285991\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977babed",
   "metadata": {},
   "source": [
    "## Challenge 4: Advanced sorting techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9f6f7",
   "metadata": {},
   "source": [
    "Quite often it is better to improve the things you're good at than improving the things you're bad at. So the question is, which crop is the top performer in Maji Ndogo, and under what conditions does it perform well? \n",
    "\n",
    "To answer this, we need to:\n",
    "1. Filter all the fields with an above-average `Standard_yield` (do you have flashbacks to SQL subqueries right now?).\n",
    "2. Then group by <?> crop type, using `count()`.\n",
    "3. Sort the values to get the top crop type on top.\n",
    "4. Retrieve the name of the top index. See the hint below on how to do this. \n",
    "\n",
    "**Task:** Create a function that takes a DataFrame as input, filters, groups and sorts, and outputs a string value of a crop type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3d881",
   "metadata": {},
   "source": [
    "**Hint:** When you have grouped by a column, we can access the labels of that \"index column\" using `.index`. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0deef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = MD_agric_df.groupby(\"Soil_type\").mean(numeric_only = True).sort_values(by=\"Elevation\",ascending=False)\n",
    "print(grouped_df.index[0])\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4791a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def find_ideal_fields(df):\n",
    "    # Filter all the fields with an above-average Standard_yield\n",
    "    above_avg = df[df[\"Standard_yield\"] > df[\"Standard_yield\"].mean()]\n",
    "    \n",
    "    # Then group by <?> crop type, using count()\n",
    "    groupby_crop_type = above_avg.groupby(\"Crop_type\").count().sort_values(by = \"Standard_yield\", ascending = False).index[0]\n",
    "    \n",
    "    return groupby_crop_type\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efcc079",
   "metadata": {},
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01448eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(find_ideal_fields(MD_agric_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd44b50",
   "metadata": {},
   "source": [
    "Expected output: `str`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7289df",
   "metadata": {},
   "source": [
    "# Challenge 5: Advanced filtering techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7956f3ab",
   "metadata": {},
   "source": [
    "Now we know that <?> is our most successful crop, we can look at what makes it successful.\n",
    "\n",
    "Create a function that takes a DataFrame as input, and the type of crop, and filters the DataFrame using the following conditions:\n",
    "1. Filter by crop type.\n",
    "\n",
    "2. Select only rows that have above average `Standard_yield`.\n",
    "\n",
    "3. Select only rows that have `Ave_temps` >= 12 but =< 15.\n",
    "\n",
    "4. Have a `Pollution_level` lower than 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def find_good_conditions(df, crop_type):\n",
    "     # Filter by crop type\n",
    "    conditions = (df[\"Crop_type\"] == crop_type) & (df[\"Standard_yield\"] > df[\"Standard_yield\"].mean()) & ((df[\"Ave_temps\"] >= 12) & (df[\"Ave_temps\"] <= 15)) & (df[\"Pollution_level\"] < 0.0001)\n",
    "    return df[conditions]\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc44d2",
   "metadata": {},
   "source": [
    "Input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209203d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 17)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_good_conditions(MD_agric_df, \"tea\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522fb89",
   "metadata": {},
   "source": [
    "Expected output: `(14, 17)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b4aa3",
   "metadata": {},
   "source": [
    "# Extra Pandas \"nuggets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ffa827",
   "metadata": {},
   "source": [
    "We have not even scratched the surface of Pandas or our dataset. If you remember back to your days with Chidi, it took a while before we could unlock the secrets the survey data had. So, scratch around a bit.\n",
    "\n",
    "On the Pandas front, it's the same. Pandas is a very powerful data analysis tool that takes a while to master. Many of the more advanced methods like window functions, dynamically retrieving or changing data, vectorisation, or processing big data with Pandas are all more advanced topics we encounter in the workplace.\n",
    "\n",
    "But here are two tiny 'nuggets' to upskill in Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184dc608",
   "metadata": {},
   "source": [
    "## df.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026086fc",
   "metadata": {},
   "source": [
    "Oh, you're going to love this one... `df.query()` was designed to filter data, but using SQL-like syntax. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d22c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_agric_df.query('Standard_yield > 0.5 and Soil_type == \"Loamy\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb4b96",
   "metadata": {},
   "source": [
    "Isn't that much easier to read and understand than the one below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_agric_df[(MD_agric_df['Standard_yield'] > 0.5) & (MD_agric_df['Soil_type'] == 'Loamy')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae060c3f",
   "metadata": {},
   "source": [
    "The nice thing is, we can use `in []`, `not in []` to filter with, and also pass in variables using `@variable_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cde683",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_types = ['Loamy', 'Sandy', 'Silt']\n",
    "\n",
    "MD_agric_df.query('Soil_type in @soil_types')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3f939",
   "metadata": {},
   "source": [
    "# Plotting data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d5c23",
   "metadata": {},
   "source": [
    "Sometimes we quickly want to see a basic visualisation of our data. we can use `df.plot(kind='bar')` to make a bar plot, `df.plot(kind='hist', bins = 10)` to see the distribution of a data column, or `df.plot(kind='scatter', x='Column_on_x', y='Column_on_y')` to understand the relationship between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_agric_df.groupby('Crop_type')['Standard_yield'].mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_agric_df['Standard_yield'].plot(kind='hist', bins =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MD_agric_df.plot(kind='scatter', x = \"Pollution_level\", y = \"Standard_yield\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a7d2a",
   "metadata": {},
   "source": [
    "We can use these plots to get a quick feel for the data, but we can't really customise these much. For that we need some better tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
